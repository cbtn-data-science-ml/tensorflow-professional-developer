{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CHALLENGE"
      ],
      "metadata": {
        "id": "1Y64aa7rTWoS"
      },
      "id": "1Y64aa7rTWoS"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Example dataset of song lyrics for training\n",
        "lyrics = [\n",
        "    \"Rage against the machine learning\",\n",
        "    \"Rage against the deep learning?\",\n",
        "    \"Rage against the algorithm, itâ€™s what weâ€™re yearning\",\n",
        "    \"Rage against the neural network, it keeps on churning\",\n",
        "    \"Rage against the AI, the world keeps turning\"\n",
        "]\n",
        "\n",
        "### START CHALLENGE CODE ###\n",
        "tokenizer = # Define Tokenizer: ðŸ‘€ first 50 words with OOV tokens\n",
        "tokenizer # Define Tokenize lyrics with dot notation\n",
        "word_index = # Define word_index here\n",
        "### END CHALLENGE CODE ###\n",
        "\n",
        "# Prompt user for input\n",
        "user_inputs = []\n",
        "print(\"Enter your phrases (type 'done' to finish):\")\n",
        "while True:\n",
        "    user_input = input()\n",
        "    if user_input.lower() == 'done':\n",
        "        break\n",
        "    user_inputs.append(user_input)\n",
        "\n",
        "\"\"\"\n",
        "Example User Inputs:\n",
        "\n",
        "- \"Machine learning keeps on turning\"\n",
        "- \"AI keeps churning\"\n",
        "- \"Yearning for the algorithm\"\n",
        "- \"Deep learning and burning\"\n",
        "- \"Rage against the AI\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "### START CHALLENGE CODE ###\n",
        "sequences =  # Define token sequences and pass in user_inputs\n",
        "\n",
        "padded = # Pad sequences for uniform length, padding at the end with max length of 10\n",
        "### END CHALLENGE CODE ###\n",
        "\n",
        "\n",
        "# Create a reverse mapping from indices to words\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\"\"\"\n",
        "reverse_word_index: Dict comprehension creating a dictionary\n",
        "where keys are numerical indices and values are corresponding\n",
        "words, derived by inverting the original word_index dictionary.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Function to convert sequences back to text\n",
        "def sequences_to_text(sequences, reverse_word_index):\n",
        "    texts = []\n",
        "    for sequence in sequences:\n",
        "        words = [reverse_word_index.get(i, '?') for i in sequence if i != 0]  # Exclude padding\n",
        "        texts.append(' '.join(words))\n",
        "    return texts\n",
        "\n",
        "# Show the padded sequences converted back to text\n",
        "print(\"\\nPadded Sequences Converted Back to Text (excluding padding):\")\n",
        "for text in sequences_to_text(padded, reverse_word_index):\n",
        "    print(text)\n"
      ],
      "metadata": {
        "id": "a29SJRorTXk8"
      },
      "id": "a29SJRorTXk8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOLUTION"
      ],
      "metadata": {
        "id": "DsFpxZWgTfUY"
      },
      "id": "DsFpxZWgTfUY"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Example dataset of song lyrics for training\n",
        "lyrics = [\n",
        "    \"Rage against the machine learning\",\n",
        "    \"Rage against the deep learning?\",\n",
        "    \"Rage against the algorithm, itâ€™s what weâ€™re yearning\",\n",
        "    \"Rage against the neural network, it keeps on churning\",\n",
        "    \"Rage against the AI, the world keeps turning\"\n",
        "]\n",
        "\n",
        "# Define Tokenizer: ðŸ‘€ first 50 words with OOV tokens\n",
        "tokenizer = Tokenizer(num_words=50, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(lyrics) # Tokenize lyrics with dot notation\n",
        "word_index = tokenizer.word_index # Define word_index here\n",
        "\n",
        "# Prompt user for input\n",
        "user_inputs = []\n",
        "print(\"Enter your phrases (type 'done' to finish):\")\n",
        "while True:\n",
        "    user_input = input()\n",
        "    if user_input.lower() == 'done':\n",
        "        break\n",
        "    user_inputs.append(user_input)\n",
        "\n",
        "\"\"\"\n",
        "Example User Inputs:\n",
        "\n",
        "- \"Machine learning keeps on turning\"\n",
        "- \"AI keeps churning\"\n",
        "- \"Yearning for the algorithm\"\n",
        "- \"Deep learning and burning\"\n",
        "- \"Rage against the AI\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Define token sequences and pass in user_inputs\n",
        "sequences = tokenizer.texts_to_sequences(user_inputs)\n",
        "\n",
        "# Pad sequences for uniform length, padding at the end with max length of 10\n",
        "padded = pad_sequences(sequences, padding='post', maxlen=10)\n",
        "\n",
        "# Create a reverse mapping from indices to words\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\"\"\"\n",
        "reverse_word_index: Dict comprehension creating a dictionary\n",
        "where keys are numerical indices and values are corresponding\n",
        "words, derived by inverting the original word_index dictionary.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Function to convert sequences back to text\n",
        "def sequences_to_text(sequences, reverse_word_index):\n",
        "    texts = []\n",
        "    for sequence in sequences:\n",
        "        words = [reverse_word_index.get(i, '?') for i in sequence if i != 0]  # Exclude padding\n",
        "        texts.append(' '.join(words))\n",
        "    return texts\n",
        "\n",
        "# Show the padded sequences converted back to text\n",
        "print(\"\\nPadded Sequences Converted Back to Text (excluding padding):\")\n",
        "for text in sequences_to_text(padded, reverse_word_index):\n",
        "    print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Uj0jwnZTeE3",
        "outputId": "64b71b28-0bf2-40a8-8763-7348a2ebce71"
      },
      "id": "8Uj0jwnZTeE3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your phrases (type 'done' to finish):\n",
            "Machine learning keeps on turning\n",
            "Yearning for the algorithm\n",
            "RIm burning to rage against the machine learning!\n",
            "done\n",
            "\n",
            "Original Texts from User Inputs:\n",
            "machine learning keeps on turning\n",
            "yearning <OOV> the algorithm\n",
            "<OOV> <OOV> <OOV> rage against the machine learning\n",
            "\n",
            "Padded Sequences Converted Back to Text (excluding padding):\n",
            "machine learning keeps on turning\n",
            "yearning <OOV> the algorithm\n",
            "<OOV> <OOV> <OOV> rage against the machine learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UlQ_4EW_ThIL"
      },
      "id": "UlQ_4EW_ThIL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DsFpxZWgTfUY"
      ]
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
