{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKnLi-1c1zZr"
   },
   "source": [
    "# **Time Series Forecasting with TensorFlow: DNN Baseline Model**\n",
    "\n",
    "\n",
    "\n",
    "## **1. Generate Synthetic Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvmaAbJ91zZu"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Generate synthetic time series data\n",
    "time = # 1200 time steps\n",
    "series = # Sine wave with noise\n",
    "\n",
    "# Plot the synthetic data\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(time, series)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Synthetic Time Series Data')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSSKUYpc1zZv"
   },
   "source": [
    "## **2. What is `split_time`? Explaining the slicing and visualization.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uyz_v61r1zZv"
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "\n",
    "\n",
    "# Plot the split\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(time[:split_time], x_train, label='Training Set')\n",
    "plt.plot(time[split_time:], x_valid, label='Validation Set')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Training and Validation Sets')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aG6LRFW41zZv"
   },
   "source": [
    "# **3. What is `windowed_dataset`, and why do we use it?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbQDHNHQ1zZv"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a windowed dataset function\n",
    "def windowed_dataset(series, window_size, batch_size):\n",
    "    \"\"\"\n",
    "    Create a windowed dataset for training our  model.\n",
    "\n",
    "    Parameters:\n",
    "    - series: The full time series data (wave heights).\n",
    "    - window_size: The number of data points in each window (how much of the wave).\n",
    "    - batch_size: The number of windows processed in one batch.\n",
    "\n",
    "    Returns:\n",
    "    - A TensorFlow dataset with overlapping windows and their corresponding labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Convert the time series into individual elements\n",
    "    dataset = # YOUR CODE HERE\n",
    "\n",
    "    # 2. Create windows of size (window_size + 1)\n",
    "    # Each window includes `window_size` inputs (features) and 1 label (the next value)\n",
    "    dataset = # YOUR CODE HERE\n",
    "\n",
    "    # 3. Flatten each window\n",
    "    dataset = # YOUR CODE HERE\n",
    "\n",
    "    # 4. Split each window into features and labels\n",
    "    dataset = # YOUR CODE HERE\n",
    "\n",
    "    # 5. Shuffle the windows\n",
    "    dataset = # YOUR CODE HERE\n",
    "\n",
    "    # Return the prepared dataset\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Define parameters\n",
    "window_size = # YOUR CODE HERE\n",
    "batch_size = # YOUR CODE HERE\n",
    "\n",
    "# Create windowed datasets\n",
    "train_dataset = # YOUR CODE HERE\n",
    "valid_dataset = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rStAvtPc1zZv"
   },
   "source": [
    "## **4. What is the model seeing and learning?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3TvTHG51zZw"
   },
   "outputs": [],
   "source": [
    "# Visualize a single sample window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibJROqFi1zZw"
   },
   "source": [
    "## **5. Build and Compile the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdrE3wii1zZw"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = # YOUR CODE HERE\n",
    "\n",
    "# Compile the model\n",
    "model. # YOUR CODE HERE\n",
    "model. # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_s-F1gNF1zZw"
   },
   "source": [
    "## **6. Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_qHszwf1zZw"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mM_z8vc1zZw"
   },
   "source": [
    "## **7. Plot performance using lossâ€”NOT accuracy.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNsYz5nC1zZw"
   },
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osk2Uumj1zZx"
   },
   "source": [
    "## **8. Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFPVDlh51zZx"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "\n",
    "\n",
    "# Plot predictions vs. true values\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMHOQpl4w0/ZeafaWfmy7gz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
