{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c8c9262-8c3d-4d62-8f71-2ce127a0ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cbtn-data-science-ml/ml_datasets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5616bfcd-c8a2-4baa-9ccb-735b19fae79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9444d01-0a2c-46fc-95dd-b23d4c06dbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ml_datasets'...\n",
      "remote: Enumerating objects: 38081, done.\u001b[K\n",
      "remote: Counting objects: 100% (13077/13077), done.\u001b[K\n",
      "remote: Compressing objects: 100% (13072/13072), done.\u001b[K\n",
      "remote: Total 38081 (delta 7), reused 13064 (delta 0), pack-reused 25004\u001b[K\n",
      "Receiving objects: 100% (38081/38081), 1.14 GiB | 2.75 MiB/s, done.\n",
      "Resolving deltas: 100% (9/9), done.\n",
      "Updating files: 100% (39804/39804), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/cbtn-data-science-ml/ml_datasets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890f3cbb-6b9a-4a39-9865-e5a3ca2ae74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('ml_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4746e28d-e658-41e4-8a43-71441dbd7f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/11_improve_tl_w_callbacks/ml_datasets\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3728b25f-3b51-42c1-aa80-66439947600b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md         \u001b[34mfood_10\u001b[m\u001b[m           \u001b[34mreduced_dataset\u001b[m\u001b[m\n",
      "\u001b[34mcats_vs_dogs\u001b[m\u001b[m      \u001b[34mramen_sushi\u001b[m\u001b[m       \u001b[34mwaffles_or_nachos\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3a779b8-920d-4f7d-bc07-13747cf18ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'reduced_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17c220b4-f5df-4c30-b164-ae231779cc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# update hyperparams\n",
    "IMAGE_SHAPE = (200, 200)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    'food_10/test',\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "039127c6-aecd-4a98-9eb8-f81de878ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cfc8b54-cd03-4d51-87bb-bc854ced1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Callback\n",
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') > 0.2):\n",
    "            print(\"/nAccuracy is > 20%: STOPPPING\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "my_callbacks = MyCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81c83c51-2cbf-4d93-8dcc-9ce531afd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined Callbacks\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b143b06-ea69-44d8-a005-32ce4f546769",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir='./logs')\n",
    "\n",
    "# model.fit(\n",
    "#     path,\n",
    "#     epochs,\n",
    "#     test_set,\n",
    "#     callbacks=[tensorboard_callback]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde976f-7943-4dc2-a53f-9760e483c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bc44c1-e8d4-4d6b-a77a-dccb490247b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb013474-9055-4469-a0d3-d042ca6e895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize and Debug ML models\n",
    "# Uses: viz learning curves\n",
    "# Mitigating Overfitting\n",
    "# Images, Audio, Text(NLP), embedding projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca0721c9-18d0-45ab-ae43-3233f9a04463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint: saves the model or weights at certain points, allows you to recover models or checkpoints from trainnig.\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath= './best_model',\n",
    "    save_best_only = True,\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ba056-6706-46b2-8564-bb884562ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     path,\n",
    "#     epochs,\n",
    "#     test_set,\n",
    "#     callbacks=[model_checkpoint_callback]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fffc7bc4-f89d-453e-ab35-3c0c74d4fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f2906-ddde-4e47-a9a9-549d20a2097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     path,\n",
    "#     epochs,\n",
    "#     test_set,\n",
    "#     callbacks=[early_stopping_callback]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601b911-c0bd-4d5c-9e48-3d8e3bf00b6f",
   "metadata": {},
   "source": [
    "### Combined Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0de0a-be05-4a18-be56-61cb7c0a055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks=[tensorboard_callback, model_checkpoint_callback, early_stopping_callback]\n",
    "# model.fit(\n",
    "#     path,\n",
    "#     epochs,\n",
    "#     test_set,\n",
    "#     callbacks=callbacks\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
