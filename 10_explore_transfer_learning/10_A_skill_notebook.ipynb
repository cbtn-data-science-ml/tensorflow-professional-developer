{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3a4b8b4-8693-4162-bdf0-99f3ce5eb35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f60f8b3b-5749-4492-a188-f80bfeb0a937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ml_datasets'...\n",
      "remote: Enumerating objects: 38062, done.\u001b[K\n",
      "remote: Counting objects: 100% (13058/13058), done.\u001b[K\n",
      "remote: Compressing objects: 100% (13055/13055), done.\u001b[K\n",
      "remote: Total 38062 (delta 5), reused 13052 (delta 0), pack-reused 25004\u001b[K\n",
      "Receiving objects: 100% (38062/38062), 1.14 GiB | 2.78 MiB/s, done.\n",
      "Resolving deltas: 100% (7/7), done.\n",
      "Updating files: 100% (40527/40527), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/cbtn-data-science-ml/ml_datasets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7de4cd81-abb4-4bdc-8868-c091b337df4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "979724f9-7d1e-47c1-8b66-7b4bb14e5fd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ml_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[0;32m----> 2\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mml_datasets\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ml_datasets'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('ml_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65739c69-72bf-4581-8870-e54b977db9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md           model_utils.py      \u001b[34mramen_sushi\u001b[m\u001b[m         \u001b[34mtest_images\u001b[m\u001b[m\n",
      "\u001b[34mfood_10\u001b[m\u001b[m             \u001b[34mnlp_disaster_tweets\u001b[m\u001b[m \u001b[34msunspots\u001b[m\u001b[m            \u001b[34mwaffles_or_nachos\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f931c6c9-8261-4e67-90ac-4b08460a4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE = (200, 200)\n",
    "BACTH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b602f63b-dd29-47a2-86fe-1196f0c15010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train/churros\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset/churros\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train/greek_salad\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset/greek_salad\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train/beef_tartare\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset/beef_tartare\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train/guacamole\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset/guacamole\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train/strawberry_shortcake\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset/strawberry_shortcake\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train/pad_thai\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset/pad_thai\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train/sushi\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset/sushi\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train/pancakes\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset/pancakes\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train/french_onion_soup\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset/french_onion_soup\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train/pho\n",
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset/pho\n"
     ]
    }
   ],
   "source": [
    "# Set your dataset path\n",
    "dataset_path = '/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/food_10/train'\n",
    "reduced_dataset_path = '/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset'\n",
    "\n",
    "# Ensure the reduced dataset directory exists\n",
    "os.makedirs(reduced_dataset_path, exist_ok=True)\n",
    "\n",
    "# Set dataset size (0.1 for 10%)\n",
    "reduction = 0.1\n",
    "\n",
    "# Reduce the dataset size\n",
    "for item in os.listdir(dataset_path):\n",
    "    print(dataset_path)\n",
    "    class_path = os.path.join(dataset_path, item)\n",
    "    print(class_path)\n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(class_path):\n",
    "        reduced_class_path = os.path.join(reduced_dataset_path, item)\n",
    "        os.makedirs(reduced_class_path, exist_ok=True)\n",
    "        print(reduced_class_path)\n",
    "        # Filter out only files (mostly images) from the directory\n",
    "        images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "        reduced_size = int(len(images) * reduction)\n",
    "\n",
    "        selected_images = random.sample(images, reduced_size)\n",
    "        for image in selected_images:\n",
    "            shutil.copy(os.path.join(class_path, image), os.path.join(reduced_class_path, image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da1d81d-b0cc-4ebc-864c-0a72423de51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
