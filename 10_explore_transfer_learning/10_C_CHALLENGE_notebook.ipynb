{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a4b8b4-8693-4162-bdf0-99f3ce5eb35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f60f8b3b-5749-4492-a188-f80bfeb0a937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ml_datasets'...\n",
      "remote: Enumerating objects: 38049, done.\u001b[K\n",
      "remote: Counting objects: 100% (13045/13045), done.\u001b[K\n",
      "remote: Compressing objects: 100% (13042/13042), done.\u001b[K\n",
      "remote: Total 38049 (delta 4), reused 13041 (delta 0), pack-reused 25004\u001b[K\n",
      "Receiving objects: 100% (38049/38049), 1.14 GiB | 11.43 MiB/s, done.\n",
      "Resolving deltas: 100% (6/6), done.\n",
      "Updating files: 100% (39004/39004), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/cbtn-data-science-ml/ml_datasets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "979724f9-7d1e-47c1-8b66-7b4bb14e5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('ml_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de4cd81-abb4-4bdc-8868-c091b337df4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md         \u001b[34mfood_10\u001b[m\u001b[m           \u001b[34mreduced_dataset\u001b[m\u001b[m\n",
      "\u001b[34mcats_vs_dogs\u001b[m\u001b[m      \u001b[34mramen_sushi\u001b[m\u001b[m       \u001b[34mwaffles_or_nachos\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65739c69-72bf-4581-8870-e54b977db9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f931c6c9-8261-4e67-90ac-4b08460a4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE = (200, 200)\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b602f63b-dd29-47a2-86fe-1196f0c15010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your dataset path\n",
    "reduced_dataset_path = '/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d56342b-3f81-419a-8f60-87d24fc3cef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/barrios/Desktop/GitHub/tensorflow-professional-developer/10_explore_transfer_learning/ml_datasets/reduced_dataset'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9b2bda5-2eb8-43c5-88b5-a24e94bd9c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1523 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Use ImageDataGenerator to load images\n",
    "# Set up ImageDataGenerator for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Creating an ImageDataGenerator for testing data with only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    reduced_dataset_path,\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Generating batches of tensor image data for testing (no augmentation here)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'food_10/test/',\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f576277c-3d81-42f7-9576-831c462f875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 08:28:09.945470: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-08 08:28:09.948824: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - ETA: 0s - loss: 2.3648 - accuracy: 0.1037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 08:28:18.963261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 13s 268ms/step - loss: 2.3648 - accuracy: 0.1037 - val_loss: 2.3009 - val_accuracy: 0.1395\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 13s 272ms/step - loss: 2.2841 - accuracy: 0.1464 - val_loss: 2.2913 - val_accuracy: 0.1620\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 13s 275ms/step - loss: 2.2523 - accuracy: 0.1648 - val_loss: 2.2564 - val_accuracy: 0.1685\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 13s 277ms/step - loss: 2.2322 - accuracy: 0.1845 - val_loss: 2.2487 - val_accuracy: 0.1750\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 13s 274ms/step - loss: 2.2053 - accuracy: 0.1957 - val_loss: 2.2332 - val_accuracy: 0.2150\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 13s 275ms/step - loss: 2.1681 - accuracy: 0.2285 - val_loss: 2.2123 - val_accuracy: 0.2080\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 13s 278ms/step - loss: 2.1074 - accuracy: 0.2574 - val_loss: 2.1315 - val_accuracy: 0.2480\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 13s 276ms/step - loss: 2.0435 - accuracy: 0.2685 - val_loss: 2.1060 - val_accuracy: 0.2285\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 13s 280ms/step - loss: 2.0374 - accuracy: 0.2764 - val_loss: 2.0335 - val_accuracy: 0.2510\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 14s 281ms/step - loss: 1.9749 - accuracy: 0.3033 - val_loss: 2.0338 - val_accuracy: 0.2620\n"
     ]
    }
   ],
   "source": [
    "# Bonus: create a baseline model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop \n",
    "\n",
    "# Building the Sequential model with Dropout layers\n",
    "model = Sequential([\n",
    "    Conv2D(filters=10, kernel_size=(3, 3),input_shape=(200, 200, 3)),\n",
    "    Activation(activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    Conv2D(10, 3, activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    Conv2D(10, 3, activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax') # 10 output neuron and softmax for mlti-class classification\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='Adam', # instead of 'adam' we can adjust the LR to improve performance with RMSprop\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad620d-b490-4e01-a8e7-ad9f8b334214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
