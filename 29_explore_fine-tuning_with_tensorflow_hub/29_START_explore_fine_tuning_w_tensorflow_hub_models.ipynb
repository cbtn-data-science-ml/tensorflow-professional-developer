{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsuhWPB2ZQWL"
   },
   "outputs": [],
   "source": [
    "# clone repo: https://github.com/cbtn-data-science-ml/tensorflow-professional-developer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAbk9xhWZRDJ"
   },
   "outputs": [],
   "source": [
    "# change directory containing the nlp_disaster_tweets directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-VGGuI_aTdh"
   },
   "outputs": [],
   "source": [
    "# download the model_utils.py file from: https://raw.githubusercontent.com/cbtn-data-science-ml/tensorflow-professional-developer/main/model_utils.py\n",
    "# import early_stopping_callback, model_checkpoint_callback, and plot_loss_and_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GnD-xB50BOd"
   },
   "outputs": [],
   "source": [
    "# import for your model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create train and test paths from the train and text csv files\n",
    "\n",
    "\n",
    "# convert train and test csv files into DataFrames using the train and test paths\n",
    "\n",
    "\n",
    "# create a function named clean_text\n",
    "\n",
    "\n",
    "# call the function and define as train_df['clean_text'] and test_df['clean_text']\n",
    "\n",
    "\n",
    "# Split train and validation data X_train, X_val, y_train, y_val using train_test_split()\n",
    "    # train_df['clean_text'] must be a string\n",
    "    # return train_df['target'] values only\n",
    "    # split data: 80% train 20% test\n",
    "    # use random_state with a seed value of 42\n",
    "\n",
    "\n",
    "# Define the Universal Sentence Encoder layer\n",
    "\n",
    "\n",
    "# build the model using Functional API\n",
    "# input layer for strings\n",
    "# custom USELayer\n",
    "# hidden dense layer\n",
    "# output layer for binary classification\n",
    "\n",
    "# build and compile the model with a learning_rate of 0.0002\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eJKzKDS5eyY"
   },
   "outputs": [],
   "source": [
    "# import numpy\n",
    "\n",
    "# Convert the data to NumPy arrays\n",
    "X_train_array =  # Specify dtype=object for string data\n",
    "X_val_array =   # Specify dtype=object for string data\n",
    "\n",
    "\n",
    "# Train the model: use NumPy array format for X_train and X_val\n",
    "\n",
    "\n",
    "# Display the model summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPupb6-uc9b7"
   },
   "outputs": [],
   "source": [
    "# plot accuracy and loss"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
