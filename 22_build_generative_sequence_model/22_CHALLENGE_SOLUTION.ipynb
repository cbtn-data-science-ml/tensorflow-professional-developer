{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c734c6-4c37-4615-b922-22ab75ff28a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/barrios/opt/anaconda3/envs/tf_pro_dev\n",
      "\n",
      "  added / updated specs:\n",
      "    - wget\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2024.8.30  |       hf0a4a13_0         155 KB  conda-forge\n",
      "    certifi-2024.8.30          |     pyhd8ed1ab_0         160 KB  conda-forge\n",
      "    libidn2-2.3.3              |       he4db4b2_0         168 KB  conda-forge\n",
      "    libunistring-0.9.10        |       h3422bc3_0         1.5 MB  conda-forge\n",
      "    openssl-1.1.1w             |       h53f4e23_0         1.6 MB  conda-forge\n",
      "    wget-1.20.3                |       hb616509_1         797 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  libidn2            conda-forge/osx-arm64::libidn2-2.3.3-he4db4b2_0 \n",
      "  libunistring       conda-forge/osx-arm64::libunistring-0.9.10-h3422bc3_0 \n",
      "  wget               conda-forge/osx-arm64::wget-1.20.3-hb616509_1 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2024.3.11-~ --> conda-forge::ca-certificates-2024.8.30-hf0a4a13_0 \n",
      "  certifi            pkgs/main/osx-arm64::certifi-2024.6.2~ --> conda-forge/noarch::certifi-2024.8.30-pyhd8ed1ab_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  openssl              pkgs/main::openssl-1.1.1w-h1a28f6b_0 --> conda-forge::openssl-1.1.1w-h53f4e23_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "openssl-1.1.1w       | 1.6 MB    |                                       |   0% \n",
      "libunistring-0.9.10  | 1.5 MB    |                                       |   0% \u001b[A\n",
      "\n",
      "wget-1.20.3          | 797 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libidn2-2.3.3        | 168 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "certifi-2024.8.30    | 160 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2024 | 155 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "certifi-2024.8.30    | 160 KB    | ###7                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "openssl-1.1.1w       | 1.6 MB    | 3                                     |   1% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "certifi-2024.8.30    | 160 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libidn2-2.3.3        | 168 KB    | ###5                                  |  10% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libidn2-2.3.3        | 168 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "libunistring-0.9.10  | 1.5 MB    | ################1                     |  44% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 1.6 MB    | #################2                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2024 | 155 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-1.1.1w       | 1.6 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "libunistring-0.9.10  | 1.5 MB    | ##################################### | 100% \u001b[A\n",
      "libunistring-0.9.10  | 1.5 MB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "wget-1.20.3          | 797 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge wget -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "590aa98e-a0fb-4739-b803-a220f5fc4145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-23 10:55:54--  https://www.gutenberg.org/files/1041/1041-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 100231 (98K) [text/plain]\n",
      "Saving to: ‘tiny_corpus.txt’\n",
      "\n",
      "tiny_corpus.txt     100%[===================>]  97.88K   616KB/s    in 0.2s    \n",
      "\n",
      "2024-10-23 10:55:55 (616 KB/s) - ‘tiny_corpus.txt’ saved [100231/100231]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Part 1: Download and Load the Corpus\n",
    "!wget https://www.gutenberg.org/files/1041/1041-0.txt -O tiny_corpus.txt\n",
    "with open('tiny_corpus.txt', 'r', encoding='utf-8') as file:\n",
    "    corpus = file.read()\n",
    "\n",
    "# Use a larger subset of the corpus to improve training\n",
    "corpus = corpus[:500000]  # Limit the corpus size to 500,000 characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0641b2ca-3fe1-4f04-a379-6ba81be518c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Initialize and Fit the Text Vectorization Layer\n",
    "# corpus_lines = corpus.split('\\n')\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(corpus_lines).batch(1024)  # Batch to reduce memory usage\n",
    "\n",
    "# Define TextVectorization layer\n",
    "vectorizer = keras.layers.TextVectorization(output_mode='int', output_sequence_length=None)\n",
    "vectorizer.adapt(text_ds)\n",
    "\n",
    "# Convert the entire corpus to a sequence of numbers\n",
    "sequence = vectorizer(corpus_lines)\n",
    "input_sequences = []\n",
    "\n",
    "# Generate n-grams from the numerical representation\n",
    "for seq in sequence:\n",
    "    for i in range(1, len(seq)):\n",
    "        n_gram_sequence = seq[:i + 1]\n",
    "        input_sequences.append(n_gram_sequence.numpy())\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Create X and y from the Padded Sequences\n",
    "Xs = \n",
    "labels =\n",
    "ys ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005884cf-9e92-4b6f-b3d2-a4a06700235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Define and Compile the Model using Sequential API\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(vectorizer.get_vocabulary()),output_dim=64),\n",
    "    SimpleRNN(64),\n",
    "    Dropout(0.7),\n",
    "    Dense(len(vectorizer.get_vocabulary()), activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(Xs, ys, epochs=10, batch_size=128, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc3e3b-bdab-49ac-9b45-a23760980b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4: Plot Training History\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    if 'val_accuracy' in history.history:\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9265c8b4-045e-40c7-8445-12f4b674a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5: Generate Shakespearean-like Text\n",
    "def generate_text(model, vectorizer, seed_text, max_sequence_len, next_words=10, temperature=1.0):\n",
    "    for _ in range(next_words):\n",
    "        token_list = vectorizer([seed_text])\n",
    "        token_list = keras.preprocessing.sequence.pad_sequences(token_list, maxlen=max_sequence_len - 1, padding='pre')\n",
    "\n",
    "        probabilities = model.predict(token_list, verbose=0)[0]\n",
    "        probabilities = np.log(probabilities + 1e-7) / temperature\n",
    "        exp_preds = np.exp(probabilities)\n",
    "        probabilities = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        predicted_index = np.random.choice(len(probabilities), p=probabilities)\n",
    "\n",
    "        if predicted_index != 0:\n",
    "            output_word = vectorizer.get_vocabulary()[predicted_index]\n",
    "            seed_text += \" \" + output_word\n",
    "    return seed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b77794-d512-48c9-9228-4805a8694402",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"ROMEO:\"\n",
    "print(generate_text(model, vectorizer, seed_text, max_sequence_len=max_sequence_len, next_words=20, temperature=0.8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
