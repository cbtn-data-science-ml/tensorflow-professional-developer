{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c734c6-4c37-4615-b922-22ab75ff28a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge wget -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "590aa98e-a0fb-4739-b803-a220f5fc4145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-23 15:49:45--  https://www.gutenberg.org/files/1041/1041-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 100231 (98K) [text/plain]\n",
      "Saving to: ‘tiny_corpus.txt’\n",
      "\n",
      "tiny_corpus.txt     100%[===================>]  97.88K   434KB/s    in 0.2s    \n",
      "\n",
      "2024-10-23 15:49:46 (434 KB/s) - ‘tiny_corpus.txt’ saved [100231/100231]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Part 1: Download and Load the Corpus\n",
    "!wget https://www.gutenberg.org/files/1041/1041-0.txt -O tiny_corpus.txt\n",
    "with open('tiny_corpus.txt', 'r', encoding='utf-8') as file:\n",
    "    corpus = file.read()\n",
    "\n",
    "# Use a larger subset of the corpus to improve training\n",
    "corpus = corpus[:500000]  # Limit the corpus size to 500,000 characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0641b2ca-3fe1-4f04-a379-6ba81be518c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:49:56.311046: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Part 2: Initialize and Fit the Text Vectorization Layer\n",
    "corpus_lines = corpus.split('\\n')\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(corpus_lines).batch(1024)  # Batch to reduce memory usage\n",
    "\n",
    "# Define TextVectorization layer\n",
    "vectorizer = keras.layers.TextVectorization(output_mode='int', output_sequence_length=None)\n",
    "vectorizer.adapt(text_ds)\n",
    "\n",
    "# Convert the entire corpus to a sequence of numbers\n",
    "sequence = vectorizer(corpus_lines)\n",
    "input_sequences = []\n",
    "\n",
    "# Generate n-grams from the numerical representation\n",
    "for seq in sequence:\n",
    "    for i in range(1, len(seq)):\n",
    "        n_gram_sequence = seq[:i + 1]\n",
    "        input_sequences.append(n_gram_sequence.numpy())\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Create X and y from the Padded Sequences\n",
    "Xs = input_sequences[:, :-1]\n",
    "labels = input_sequences[:, -1]\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=len(vectorizer.get_vocabulary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005884cf-9e92-4b6f-b3d2-a4a06700235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024-10-23 10:55:56.200112: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
    "# Part 3: Define and Compile the Model using Sequential API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc3e3b-bdab-49ac-9b45-a23760980b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4: Plot Training History\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    if 'val_accuracy' in history.history:\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9265c8b4-045e-40c7-8445-12f4b674a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5: Generate Shakespearean-like Text\n",
    "def generate_text(model, vectorizer, seed_text, max_sequence_len, next_words=10, temperature=1.0):\n",
    "    for _ in range(next_words):\n",
    "        token_list = vectorizer([seed_text])\n",
    "        token_list = keras.preprocessing.sequence.pad_sequences(token_list, maxlen=max_sequence_len - 1, padding='pre')\n",
    "\n",
    "        probabilities = model.predict(token_list, verbose=0)[0]\n",
    "        probabilities = np.log(probabilities + 1e-7) / temperature\n",
    "        exp_preds = np.exp(probabilities)\n",
    "        probabilities = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        predicted_index = np.random.choice(len(probabilities), p=probabilities)\n",
    "\n",
    "        if predicted_index != 0:\n",
    "            output_word = vectorizer.get_vocabulary()[predicted_index]\n",
    "            seed_text += \" \" + output_word\n",
    "    return seed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b77794-d512-48c9-9228-4805a8694402",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"ROMEO:\"\n",
    "print(generate_text(model, vectorizer, seed_text, max_sequence_len=max_sequence_len, next_words=20, temperature=0.8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
