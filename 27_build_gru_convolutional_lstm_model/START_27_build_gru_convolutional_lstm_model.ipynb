{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sMr5paJlFPu"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/cbtn-data-science-ml/tensorflow-professional-developer/main/model_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fJnvd9w1j79"
      },
      "outputs": [],
      "source": [
        "from model_utils import plot_loss_and_accuracy, early_stopping_callback, model_checkpoint_callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1IwKT0kZ4NG"
      },
      "outputs": [],
      "source": [
        "# Clone repo\n",
        "!git clone https://github.com/cbtn-data-science-ml/tensorflow-professional-developer.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Feature                | `!cd` (Shell Command)       | `%cd` (Magic Command)                  |\n",
        "|------------------------|-----------------------------|----------------------------------------|\n",
        "| **Scope**             | Temporary (subshell only)   | Persistent (notebook-wide)            |\n",
        "| **Effect on Notebook**| No effect on working dir    | Changes notebook's working dir        |\n",
        "| **Use Case**          | One-off shell commands      | Lasting directory changes             |"
      ],
      "metadata": {
        "id": "J9kyRZjTYj7I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SotgsiwGZ4NG"
      },
      "outputs": [],
      "source": [
        "# Print working directory !pwd or %pwd?\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU5K6764Z4NG"
      },
      "outputs": [],
      "source": [
        "# Change directory\n",
        "%cd '/content/tensorflow-professional-developer'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dropout\n"
      ],
      "metadata": {
        "id": "OTxM1ZR_sBQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'nlp_disaster_tweets/train.csv'\n",
        "test_path = 'nlp_disaster_tweets/test.csv'\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)"
      ],
      "metadata": {
        "id": "kqfxnrk1O2E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "_J95sN2-AMlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "i_kIVaCYUFKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['text'].tail()"
      ],
      "metadata": {
        "id": "tgT-iBaFUu3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Good idea to shuffle the data\n",
        "train_df = train_df.sample(frac=1, random_state=42)\n",
        "test_df = test_df.sample(frac=1, random_state=42)"
      ],
      "metadata": {
        "id": "_-eq-V-tap7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['text'].tail()"
      ],
      "metadata": {
        "id": "7mlxJig-a7_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.target.value_counts() # Is the dataset balanced? close enought to 50/50 IMO\n",
        "# If imbalanced see: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
      ],
      "metadata": {
        "id": "ltgED9VhdJ3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "id": "yENAkW3PxKE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 5 random tweets and their classification\n",
        "random_samples = train_df.sample(n=10, random_state=42)\n",
        "print(random_samples[['text', 'target']])"
      ],
      "metadata": {
        "id": "hBfKFcw606zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the training dataset\n",
        "print(train_df.info())\n",
        "print(train_df.describe())"
      ],
      "metadata": {
        "id": "ypNhKH8uAIj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the test dataset\n",
        "print(test_df.info())\n",
        "print(test_df.describe())"
      ],
      "metadata": {
        "id": "pCAG_uK_UkFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate word counts for each tweet\n",
        "train_df['word_count'] = train_df['text'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(train_df['word_count'], bins=30, kde=True)\n",
        "plt.title('Word Count Distribution in Tweets')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Wyj-eXiCAUkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='target', data=random_samples)\n",
        "plt.title('Class Distribution in Random Samples')\n",
        "plt.xlabel('Disaster Tweets (1) vs. Non-Disaster Tweets (0)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "__VrMO7KB6kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge"
      ],
      "metadata": {
        "id": "AtY8NLrxGQRZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM4uwjkCHPkq"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Preprocessing\n",
        "nltk.download('stopwords') # 'the', 'is', 'in', 'and'\n",
        "\n",
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "  text = re.sub(r'<.*?>', '', text)\n",
        "  text = re.sub(r'[^a-z\\s]', '', text)\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  text = \" \".join([word for word in text.split() if word not in stop_words])\n",
        "  return text\n",
        "\n",
        "train_df['text_clean'] = train_df['text'].apply(clean_text)\n",
        "test_df['text_clean'] = test_df['text'].apply(clean_text)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}