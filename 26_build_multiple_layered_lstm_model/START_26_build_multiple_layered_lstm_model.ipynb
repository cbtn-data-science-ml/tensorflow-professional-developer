{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfULsCGYZwYR"
   },
   "source": [
    "\n",
    "\n",
    "### Conv/LSTM Equations with Markdown:\n",
    "\n",
    "1. **Input Gate** (\\(i_t\\)):\n",
    "   $$ i_t = \\sigma(W_{xi} \\ast x_t + W_{hi} \\ast h_{t-1} + W_{ci} \\circ C_{t-1} + b_i) $$\n",
    "   Decides what new information is added to the cell state, with convolution $\\ast$ applied to inputs and the previous hidden state, and an element-wise multiplication $\\circ$ with the previous cell state.\n",
    "\n",
    "2. **Forget Gate** (\\(f_t\\)):\n",
    "   $$ f_t = \\sigma(W_{xf} \\ast x_t + W_{hf} \\ast h_{t-1} + W_{cf} \\circ C_{t-1} + b_f) $$\n",
    "   Decides what information is discarded from the cell state, utilizing the same convolutional and element-wise operations to weigh the inputs, previous hidden state, and previous cell state.\n",
    "\n",
    "3. **Cell State** (\\(C_t\\)):\n",
    "   $$ C_t = f_t \\circ C_{t-1} + i_t \\circ \\tanh(W_{xc} \\ast x_t + W_{hc} \\ast h_{t-1} + b_c) $$\n",
    "   Updates the cell state by forgetting selected past information and adding new candidate values, modulated by the input and forget gates' outputs and processed through convolutional layers.\n",
    "\n",
    "4. **Output Gate** (\\(o_t\\)):\n",
    "   $$ o_t = \\sigma(W_{xo} \\ast x_t + W_{ho} \\ast h_{t-1} + W_{co} \\circ C_t + b_o) $$\n",
    "   Decides the next hidden state by filtering the cell state's content, with the convolution applied to inputs and the previous hidden state, and element-wise multiplication with the current cell state.\n",
    "\n",
    "5. **Hidden State** (\\(h_t\\)):\n",
    "   $$ h_t = o_t \\circ \\tanh(C_t) $$\n",
    "   The final hidden state output for the current time step, combining the output gate's decision with the activated cell state to produce the next hidden state that carries both spatial and temporal information.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sMr5paJlFPu",
    "outputId": "5b77e5c7-8e38-4695-bc87-9f3fcb234cdf"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/cbtn-data-science-ml/tensorflow-professional-developer/main/model_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fJnvd9w1j79"
   },
   "outputs": [],
   "source": [
    "from model_utils import plot_loss_and_accuracy, early_stopping_callback, model_checkpoint_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vb2v9Z22mMq",
    "outputId": "ca2e8f8f-b3fa-4aa6-dd87-576691000455"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9kyRZjTYj7I"
   },
   "source": [
    "| Feature                | `!cd` (Shell Command)       | `%cd` (Magic Command)                  |\n",
    "|------------------------|-----------------------------|----------------------------------------|\n",
    "| **Scope**             | Temporary (subshell only)   | Persistent (notebook-wide)            |\n",
    "| **Effect on Notebook**| No effect on working dir    | Changes notebook's working dir        |\n",
    "| **Use Case**          | One-off shell commands      | Lasting directory changes             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6BYZ7CRi2mMq",
    "outputId": "5d014bdd-9c99-477d-f2d6-332edd289aa5"
   },
   "outputs": [],
   "source": [
    "# Print working directory !pwd or % pwd?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KxsyyIp12mMr",
    "outputId": "b15a87aa-82a0-44dd-8a2c-4c5fcdf39a51"
   },
   "outputs": [],
   "source": [
    "# Change directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPd9KBo0X702",
    "outputId": "6ea78c1b-9bd6-4f51-b31f-147dd4deffd9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTxM1ZR_sBQs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqfxnrk1O2E_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J95sN2-AMlp"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "i_kIVaCYUFKz",
    "outputId": "805f8d2d-df0a-4fc0-ffce-4412380bc332"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "id": "tgT-iBaFUu3h",
    "outputId": "90bf8fc3-6178-4b57-f305-3d13f8790002"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-eq-V-tap7H"
   },
   "outputs": [],
   "source": [
    "# Good idea to shuffle the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "7mlxJig-a7_s",
    "outputId": "911f6f3b-e339-452a-cf34-82761546c74b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "ltgED9VhdJ3I",
    "outputId": "a146eafe-6b26-4220-c480-e94510e900fe"
   },
   "outputs": [],
   "source": [
    "# Is the dataset balanced? close enought to 50/50 IMO\n",
    "# if imbalanced see: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yENAkW3PxKE7",
    "outputId": "7f946a6e-5fb5-4e19-e6d1-abb1d1d0088d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBfKFcw606zH",
    "outputId": "8156933c-16dd-44f2-bdd9-781e92186dac"
   },
   "outputs": [],
   "source": [
    "# Sample 5 random tweets and their classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypNhKH8uAIj8",
    "outputId": "83c921f0-9937-4627-f0e9-7f72520765eb"
   },
   "outputs": [],
   "source": [
    "# For the training dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCAG_uK_UkFk",
    "outputId": "8eb2fd13-4a12-4ee2-fb30-c19a6ae23ac2"
   },
   "outputs": [],
   "source": [
    "# For the test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "Wyj-eXiCAUkD",
    "outputId": "4df3d03d-c67f-4e8c-f496-81c28c8eb802"
   },
   "outputs": [],
   "source": [
    "# Calculate word counts for each tweet\n",
    "train_df['word_count'] = train_df['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['word_count'], bins=30, kde=True)\n",
    "plt.title('Word Count Distribution in Tweets')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "__VrMO7KB6kr",
    "outputId": "9b938e30-10f4-4d96-91dd-78ff63e2e14f"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='target', data=random_samples)\n",
    "plt.title('Class Distribution in Random Samples')\n",
    "plt.xlabel('Disaster Tweets (1) vs. Non-Disaster Tweets (0)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vM4uwjkCHPkq"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "\n",
    "# Data paths\n",
    "\n",
    "\n",
    "# Load data\n",
    "\n",
    "\n",
    "# Shuffle data\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tokenization and padding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSA0f6w6H7t3"
   },
   "outputs": [],
   "source": [
    "# Build, train, and compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqT-jRjgNiPT"
   },
   "source": [
    "# LSTM Architecture\n",
    "LSTM layers help models to both remember details from long ago and forget irrelevant data, perfect for complex tasks where the sequence and context of information (like the unfolding of a story) matter a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yH5kpwEOIgxj"
   },
   "outputs": [],
   "source": [
    "# LSTM Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LR0I6j0LSZec"
   },
   "outputs": [],
   "source": [
    "# After training, plot the loss and accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpyPVZ4MNds2"
   },
   "source": [
    "# GRU model\n",
    "\n",
    "A GRU layer helps the model remember and use past information to make decisions, making it great for tasks where understanding the sequence or flow of data (like the order of words in a sentence) is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqEcf9taH_v3"
   },
   "outputs": [],
   "source": [
    "# GRU model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNrsn_KaItNR"
   },
   "outputs": [],
   "source": [
    "# GRU Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sk3pNic6Sea6"
   },
   "outputs": [],
   "source": [
    "# After training, plot the loss and accuracy\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
